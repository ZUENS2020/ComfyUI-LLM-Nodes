<div align="center">

# ComfyUI Gemini LiteLLM Nodes

<p>
    <a href="#en">English</a> | <a href="#cn">ä¸­æ–‡</a>
</p>

<p>
    <b>Gemini 3 Chat & Image Generation via LiteLLM</b><br>
    Multimodal Support Â· Multi-Image Reference Â· Zero Dependencies
</p>

<p>
    <a href="https://github.com/ZUENS2020/ComfyUI-Gemini-LiteLLM">GitHub</a> Â· 
    <a href="https://github.com/ZUENS2020/ComfyUI-Gemini-LiteLLM/issues">Issues</a> Â· 
    <a href="https://github.com/ZUENS2020/ComfyUI-Gemini-LiteLLM/releases">Releases</a>
</p>

</div>

<hr>

<div id="en">

## âœ¨ Features

- **Chat**: Gemini 3 conversation via LiteLLM
- **Image**: Gemini 3 image generation with resolution/aspect ratio control
- **Multimodal**: Support for multiple reference images + text
- **Temperature**: 0-1 range control for generation randomness
- **Zero Deps**: Uses only Python standard library `urllib`
- **Clean Logs**: Only error messages are displayed

## ğŸ“‹ Nodes

### Execution Nodes

| Node | Function | Inputs | Outputs |
|------|----------|--------|---------|
| **Chat** | Multimodal Chat | config, prompt, system, [image_1..5] | text |
| **Image** | Image Gen/Edit | config, prompt, n, [image_1..5], [additional_text] | image |

> `[...]` indicates optional inputs for multimodal generation.

### Config Nodes

| Node | Function | Settings |
|------|----------|----------|
| **Base Config** | API Setup | API Base, Key, Model |
| **Chat Params** | Chat Settings | Temperature, Max Tokens |
| **Image Params** | Image Settings | Aspect Ratio, Size, Temperature |

## ğŸ¯ Quick Start

### 1. Chat

```
Base Config â†’ Chat Params â†’ Chat â†’ Output
```

### 2. Image Generation

```
Base Config â†’ Image Params â†’ Image â†’ Output
```

### 3. Multimodal (Image + Text)

```
Load Image â”€â”€â”€â”€â”€â”€â”
               â”œâ†’ Image Params â†’ Image
Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Additional â”€â”€â”€â”€â”˜
```

## ğŸ¨ Image Generation Details

### Resolution & Ratio

| Size | Pixels | Ratio | Usage |
|------|--------|-------|-------|
| **1K** | ~1M | **1:1** | Square / Avatar |
| **2K** | ~4M | **16:9** | Widescreen |
| **4K** | ~16M | **9:16** | Mobile / Portrait |

### Temperature

- **0.0**: Deterministic, stable
- **0.5**: Balanced (Recommended)
- **1.0**: Creative, random

</div>

<hr>

<div id="cn">

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- **èŠå¤©å¯¹è¯**: é€šè¿‡ LiteLLM ä½¿ç”¨ Gemini 3
- **å›¾ç‰‡ç”Ÿæˆ**: æ”¯æŒåˆ†è¾¨ç‡å’Œå®½é«˜æ¯”æ§åˆ¶
- **å¤šæ¨¡æ€**: æ”¯æŒå¤šå¼ å‚è€ƒå›¾ + æ–‡æœ¬è”åˆç”Ÿæˆ
- **æ¸©åº¦æ§åˆ¶**: 0-1 èŒƒå›´å¯è°ƒï¼Œæ§åˆ¶éšæœºæ€§
- **é›¶ä¾èµ–**: ä»…ä½¿ç”¨ Python æ ‡å‡†åº“ `urllib`
- **ç²¾ç®€æ—¥å¿—**: ä»…æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯

## ğŸ“‹ èŠ‚ç‚¹åˆ—è¡¨

### æ‰§è¡ŒèŠ‚ç‚¹

| èŠ‚ç‚¹åç§° | åŠŸèƒ½æè¿° | è¾“å…¥ | è¾“å‡º |
|---------|--------|------|------|
| **Chat** | å¤šæ¨¡æ€èŠå¤© | config, prompt, system, [image_1..5] | text |
| **Image** | å›¾ç‰‡ç”Ÿæˆ | config, prompt, n, [image_1..5], [additional_text] | image |

> `[...]` è¡¨ç¤ºå¯é€‰è¾“å…¥ï¼Œæ”¯æŒå¤šæ¨¡æ€ç”Ÿæˆã€‚

### é…ç½®èŠ‚ç‚¹

| èŠ‚ç‚¹åç§° | åŠŸèƒ½ | é…ç½®é¡¹ |
|---------|------|--------|
| **Base Config** | åŸºç¡€é…ç½® | APIåœ°å€ã€å¯†é’¥ã€æ¨¡å‹ |
| **Chat Params** | èŠå¤©å‚æ•° | æ¸©åº¦ã€æœ€å¤§ä»¤ç‰Œæ•° |
| **Image Params** | å›¾ç‰‡å‚æ•° | å®½é«˜æ¯”ã€åˆ†è¾¨ç‡ã€æ¸©åº¦ |

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. èŠå¤©å¯¹è¯

```
Base Config â†’ Chat Params â†’ Chat â†’ æ–‡æœ¬è¾“å‡º
```

### 2. å›¾ç‰‡ç”Ÿæˆ

```
Base Config â†’ Image Params â†’ Image â†’ å›¾ç‰‡è¾“å‡º
```

### 3. å¤šæ¨¡æ€ç”Ÿæˆï¼ˆå›¾åƒ + æ–‡æœ¬ï¼‰

```
åŠ è½½å›¾åƒ â”€â”€â”€â”€â”€â”
            â”œâ†’ Image Params â†’ Image
ç”Ÿæˆæç¤º â”€â”€â”€â”€â”€â”¤
é™„åŠ è¯´æ˜ â”€â”€â”€â”€â”€â”˜
```

## ğŸ¨ å›¾ç‰‡ç”Ÿæˆè¯¦è§£

### åˆ†è¾¨ç‡ä¸æ¯”ä¾‹

| å°ºå¯¸ | åƒç´  | æ¯”ä¾‹ | ç”¨é€” |
|------|------|------|------|
| **1K** | ~100ä¸‡ | **1:1** | æ­£æ–¹å½¢ / å¤´åƒ |
| **2K** | ~400ä¸‡ | **16:9** | å®½å± / å£çº¸ |
| **4K** | ~1600ä¸‡ | **9:16** | ç«–å± / æ‰‹æœº |

### æ¸©åº¦å‚æ•° (Temperature)

- **0.0**: ç¨³å®šï¼Œç¡®å®šæ€§å¼º
- **0.5**: å¹³è¡¡ (æ¨è)
- **1.0**: åˆ›æ„ï¼Œéšæœºæ€§å¼º

</div>

<hr>

## â“ FAQ / å¸¸è§é—®é¢˜

<details>
<summary><b>Why /chat/completions? / ä¸ºä»€ä¹ˆä½¿ç”¨ chat æ¥å£ï¼Ÿ</b></summary>
<br>
Gemini via LiteLLM uses the `/chat/completions` endpoint with `image_config` for image generation. The standard `/images/generations` endpoint returns empty data for Gemini models.
<br><br>
Gemini é€šè¿‡ LiteLLM æ—¶ï¼Œä½¿ç”¨ `/chat/completions` é…åˆ `image_config` æ˜¯æ ‡å‡†å®ç°æ–¹å¼ã€‚æ ‡å‡†çš„ `/images/generations` æ¥å£ä¼šè¿”å›ç©ºæ•°æ®ã€‚
</details>

<details>
<summary><b>Why text instead of image? / ä¸ºä»€ä¹ˆè¿”å›æ–‡æœ¬ï¼Ÿ</b></summary>
<br>
This happens if the prompt is too complex or phrased as a question. Use concise, descriptive prompts.
<br><br>
å¦‚æœæç¤ºè¯è¿‡äºå¤æ‚æˆ–åƒæ˜¯åœ¨æé—®ï¼Œå¯èƒ½ä¼šè¿”å›æ–‡æœ¬ã€‚è¯·ä½¿ç”¨ç®€æ´çš„å›¾åƒæè¿°æ€§æç¤ºè¯ã€‚
</details>

<hr>

<div align="center">
    <p>
        <a href="https://github.com/ZUENS2020/ComfyUI-Gemini-LiteLLM">GitHub Repository</a> Â· 
        <b>License</b>: MIT Â· <b>Version</b>: 3.0.0
    </p>
</div>
